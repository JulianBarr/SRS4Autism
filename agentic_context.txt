
====================
FILE: agentic/config.py
====================

from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data"
AGENT_DATA_DIR = DATA_DIR / "agent"
AGENT_DATA_DIR.mkdir(parents=True, exist_ok=True)

MEMORY_FILE = AGENT_DATA_DIR / "memory.json"

PRINCIPLES_DIR = DATA_DIR / "principles"
PRINCIPLES_DIR.mkdir(parents=True, exist_ok=True)
PRINCIPLES_FILE = PRINCIPLES_DIR / "principles.yaml"




====================
FILE: agentic/memory.py
====================

import json
from typing import Any, Dict, Optional

from .config import MEMORY_FILE


class AgentMemory:
    """
    Simple JSON-backed memory store.

    This is intentionally lightweight so that it can coexist with the
    existing system. Later, it can be swapped for a vector database without
    changing the agent interface.
    """

    def __init__(self) -> None:
        self._cache: Dict[str, Dict[str, Any]] = {}
        self._load()

    def _load(self) -> None:
        if MEMORY_FILE.exists():
            try:
                self._cache = json.loads(MEMORY_FILE.read_text())
            except json.JSONDecodeError:
                self._cache = {}
        else:
            self._cache = {}

    def _save(self) -> None:
        MEMORY_FILE.write_text(json.dumps(self._cache, indent=2, ensure_ascii=False))

    def get_profile(self, user_id: str) -> Dict[str, Any]:
        return self._cache.get(user_id, {})

    def update_profile(self, user_id: str, updates: Dict[str, Any]) -> Dict[str, Any]:
        profile = self._cache.get(user_id, {})
        profile.update(updates)
        self._cache[user_id] = profile
        self._save()
        return profile

    def append_history(self, user_id: str, entry: Dict[str, Any]) -> None:
        profile = self._cache.setdefault(user_id, {})
        history = profile.setdefault("history", [])
        history.append(entry)
        self._save()

    def get_last_interaction(self, user_id: str) -> Optional[Dict[str, Any]]:
        profile = self._cache.get(user_id, {})
        history = profile.get("history") or []
        return history[-1] if history else None




====================
FILE: agentic/tools.py
====================

"""
Wrapper tools that expose existing logic to the new agentic layer.

The agent uses these tools to:
1. Query mastery vector (from Anki review history)
2. Query world model (knowledge graph)
3. Query user profile (from memory)
4. Call recommender with cognitive prior
5. Generate flashcards when needed
"""

import logging
from typing import Any, Dict, List, Optional

from agent.content_generator import ContentGenerator
from backend.config import settings
from backend.database.kg_client import (
    KnowledgeGraphClient,
    KnowledgeGraphConnectionError,
    KnowledgeGraphQueryError,
    KnowledgeGraphError,
)

# Configure logging
logger = logging.getLogger(__name__)


# Custom exceptions for better error handling
class AgentToolsError(Exception):
    """Base exception for AgentTools errors"""
    pass


class MasteryVectorError(AgentToolsError):
    """Raised when mastery vector query fails"""
    pass


class MasteryVectorTimeoutError(MasteryVectorError):
    """Raised when mastery vector query times out"""
    pass


class KnowledgeGraphError(AgentToolsError):
    """Raised when knowledge graph query fails"""
    pass


class KnowledgeGraphTimeoutError(KnowledgeGraphError):
    """Raised when knowledge graph query times out"""
    pass


class RecommenderError(AgentToolsError):
    """Raised when recommender fails"""
    pass


class RecommenderTimeoutError(RecommenderError):
    """Raised when recommender times out"""
    pass


# Lazy imports to avoid circular dependencies
def _get_build_cuma_remarks():
    from backend.app.main import build_cuma_remarks
    return build_cuma_remarks


class AgentTools:
    """
    Tools for the agentic learning agent.

    These tools allow the agent to:
    - Query cognitive state (mastery, KG, profile)
    - Get learning recommendations
    - Generate content when needed
    """

    def __init__(self) -> None:
        self.generator = ContentGenerator()
        self._recommender = None
        self._kg_client = KnowledgeGraphClient(timeout=15)

    def _get_recommender(self):
        """Lazy load the recommender to avoid import issues."""
        if self._recommender is None:
            from scripts.knowledge_graph.curious_mario_recommender import (
                CuriousMarioRecommender,
                RecommenderConfig,
            )
            config = RecommenderConfig()
            self._recommender = CuriousMarioRecommender(config)
        return self._recommender

    def query_mastery_vector(self, user_id: str) -> Dict[str, float]:
        """
        Query the mastery vector for a user based on Anki review history.

        Returns a dictionary mapping knowledge graph node IDs to mastery scores (0.0-1.0).

        Raises:
            MasteryVectorTimeoutError: If query takes longer than 30 seconds
            MasteryVectorError: If query fails for any other reason
        """
        try:
            recommender = self._get_recommender()
            # Add timeout protection using threading (works in FastAPI)
            from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError

            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(recommender.build_mastery_vector)
                try:
                    mastery_vector = future.result(timeout=30)  # 30 second timeout
                    logger.info(f"Successfully retrieved mastery vector with {len(mastery_vector)} nodes for user {user_id}")
                    return mastery_vector
                except FutureTimeoutError as e:
                    logger.error(f"Mastery vector query timed out after 30 seconds for user {user_id}")
                    raise MasteryVectorTimeoutError(
                        f"Mastery vector query timed out after 30 seconds for user {user_id}"
                    ) from e
        except MasteryVectorTimeoutError:
            # Re-raise timeout errors as-is
            raise
        except Exception as e:
            logger.error(f"Failed to query mastery vector for user {user_id}: {e}", exc_info=True)
            raise MasteryVectorError(
                f"Failed to query mastery vector for user {user_id}: {str(e)}"
            ) from e

    def query_world_model(self, topic: Optional[str] = None, node_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Query the knowledge graph (world model) for information about a topic or node.

        Args:
            topic: Optional topic to query (e.g., "math", "chinese")
            node_id: Optional specific node ID to query

        Returns:
            Dictionary with node information, dependencies, and structure

        Raises:
            KnowledgeGraphTimeoutError: If query takes longer than 15 seconds
            KnowledgeGraphError: If query fails for any other reason
        """
        try:
            if node_id:
                # Query specific node with prerequisites
                sparql = f"""
                PREFIX srs-kg: <http://srs4autism.com/schema/>
                PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

                SELECT ?node ?label ?hsk ?prereq WHERE {{
                    BIND(<http://srs4autism.com/schema/{node_id}> AS ?node)
                    ?node rdfs:label ?label .
                    OPTIONAL {{ ?node srs-kg:hskLevel ?hsk }}
                    OPTIONAL {{ ?node srs-kg:requiresPrerequisite ?prereq }}
                }}
                """
                logger.debug(f"Querying KG for specific node: {node_id}")
            elif topic:
                # Query nodes related to topic
                sparql = f"""
                PREFIX srs-kg: <http://srs4autism.com/schema/>
                PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

                SELECT ?node ?label ?hsk ?prereq WHERE {{
                    ?node a srs-kg:Word ;
                          rdfs:label ?label .
                    OPTIONAL {{ ?node srs-kg:hskLevel ?hsk }}
                    OPTIONAL {{ ?node srs-kg:requiresPrerequisite ?prereq }}
                    FILTER(CONTAINS(LCASE(?label), LCASE("{topic}")))
                }}
                LIMIT 50
                """
                logger.debug(f"Querying KG for topic: {topic}")
            else:
                # General query for structure
                sparql = """
                PREFIX srs-kg: <http://srs4autism.com/schema/>
                PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

                SELECT (COUNT(?node) AS ?total_nodes) WHERE {
                    ?node a srs-kg:Word .
                }
                """
                logger.debug("Querying KG for general structure")

            result = self._kg_client.query(sparql)
            logger.info(f"Successfully queried KG (endpoint: {self._kg_client.endpoint_url})")
            return result

        except KnowledgeGraphConnectionError as e:
            logger.error(f"Knowledge graph query timed out or connection failed: {e}")
            raise KnowledgeGraphTimeoutError(
                f"Knowledge graph query timed out after 15 seconds (endpoint: {self._kg_client.endpoint_url})"
            ) from e
        except (KnowledgeGraphQueryError, KnowledgeGraphError) as e:
            logger.error(f"Knowledge graph request failed: {e}", exc_info=True)
            raise KnowledgeGraphError(
                f"Knowledge graph request failed: {str(e)}"
            ) from e
        except Exception as e:
            logger.error(f"Unexpected error querying knowledge graph: {e}", exc_info=True)
            raise KnowledgeGraphError(
                f"Unexpected error querying knowledge graph: {str(e)}"
            ) from e

    def query_user_profile(self, user_id: str, memory) -> Dict[str, Any]:
        """
        Query user profile from memory.
        
        This is a convenience method that wraps memory.get_profile().
        """
        return memory.get_profile(user_id)

    def call_recommender(
        self,
        user_id: str,
        cognitive_prior: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        Call the recommender with a synthesized cognitive prior.

        Note: The recommender builds its own mastery vector from Anki.
        The cognitive_prior is provided for context and future enhancements,
        but the recommender uses its own data sources.

        Args:
            user_id: User identifier
            cognitive_prior: Dictionary containing:
                - mastery_vector: Dict[str, float] - mastery scores by node ID (for reference)
                - kg_context: Dict[str, Any] - knowledge graph context
                - profile: Dict[str, Any] - user profile/preferences

        Returns:
            Dictionary with recommendation plan:
                - decision: str - "EXPLORATORY", "REMEDIAL", or "REVIEW"
                - plan_title: str - human-readable plan name
                - learning_task: str - type of task ("scaffold", "review", "rest")
                - task_details: Dict - specific task parameters
                - recommendations: List[Dict] - list of recommended nodes

        Raises:
            RecommenderTimeoutError: If recommender takes longer than 60 seconds
            RecommenderError: If recommender fails for any other reason

        Note:
            On timeout, returns a safe fallback with decision="REVIEW" to allow graceful degradation.
            Other errors will raise exceptions to signal true failures.
        """
        try:
            recommender = self._get_recommender()

            # Generate recommendations (recommender builds mastery vector internally)
            # Add timeout protection using threading (works in FastAPI)
            from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError

            with ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(recommender.generate_recommendations)
                try:
                    exploratory, remedial, mastery_vector = future.result(timeout=60)  # 60 second timeout
                except FutureTimeoutError as e:
                    logger.warning(f"Recommender timed out after 60 seconds for user {user_id}, returning fallback")
                    # Return a safe fallback response for timeout (graceful degradation)
                    return {
                        "decision": "REVIEW",
                        "plan_title": "Unable to generate recommendations (timeout)",
                        "learning_task": "rest",
                        "task_details": {},
                        "recommendations": [],
                        "mastery_summary": {
                            "total_tracked": 0,
                            "mastered_count": 0,
                        },
                        "timeout": True,  # Flag to indicate this is a timeout fallback
                    }
            
            # Determine decision based on recommendations
            if remedial:
                # Prioritize remedial if there are items needing review
                top_remedial = remedial[0] if remedial else None
                decision = "REMEDIATE"
                plan_title = f"Review and strengthen: {top_remedial.label if top_remedial else 'weak areas'}"
                learning_task = "scaffold"
                task_details = {
                    "type": "cloze",  # Remedial typically uses cloze
                    "node_id": top_remedial.node_id if top_remedial else None,
                    "count": 5,
                }
                recommendations = [
                    {
                        "node_id": rec.node_id,
                        "label": rec.label,
                        "mastery": rec.mastery,
                        "type": "remedial",
                    }
                    for rec in remedial[:5]
                ]
            elif exploratory:
                # Use exploratory recommendations
                top_exploratory = exploratory[0]
                decision = "EXPLORATORY"
                plan_title = f"Learn: {top_exploratory.label}"
                learning_task = "scaffold"
                task_details = {
                    "type": "mcq",  # Exploratory typically starts with MCQ
                    "node_id": top_exploratory.node_id,
                    "count": 3,
                }
                recommendations = [
                    {
                        "node_id": rec.node_id,
                        "label": rec.label,
                        "mastery": rec.mastery,
                        "score": rec.score,
                        "type": "exploratory",
                    }
                    for rec in exploratory[:10]
                ]
            else:
                # No recommendations - might be fully mastered or prerequisites missing
                decision = "REVIEW"
                plan_title = "Review mastered content"
                learning_task = "review"
                task_details = {"type": "review", "count": 10}
                recommendations = []
            
            result = {
                "decision": decision,
                "plan_title": plan_title,
                "learning_task": learning_task,
                "task_details": task_details,
                "recommendations": recommendations,
                "mastery_summary": {
                    "total_tracked": len(mastery_vector),
                    "mastered_count": sum(1 for v in mastery_vector.values() if v >= 0.85),
                },
            }
            logger.info(f"Successfully generated recommendations for user {user_id}: {decision} with {len(recommendations)} items")
            return result

        except Exception as e:
            logger.error(f"Failed to generate recommendations for user {user_id}: {e}", exc_info=True)
            raise RecommenderError(
                f"Failed to generate recommendations for user {user_id}: {str(e)}"
            ) from e

    def generate_flashcards(self, prompt: str, context_tags: Dict[str, Any], child_profile: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate flashcards using the existing ContentGenerator but return
        structured metadata that the agent can reason over.
        """
        cards = self.generator.generate_from_prompt(
            user_prompt=prompt,
            context_tags=context_tags,
            child_profile=child_profile,
            prompt_template=None,
        )
        build_cuma_remarks = _get_build_cuma_remarks()
        for card in cards:
            remarks = build_cuma_remarks(card, [])
            card["field__Remarks"] = remarks
        return {"cards": cards}




====================
FILE: agentic/__init__.py
====================

"""
Agentic framework package for the evolving SRS4Autism architecture.

This package contains the new Agentic RAG components that are being
introduced gradually alongside the existing rule/template driven code.
"""

from .agent import AgenticPlanner  # noqa: F401
from .memory import AgentMemory  # noqa: F401
from .principles import PrincipleStore  # noqa: F401
from .tools import AgentTools  # noqa: F401




====================
FILE: agentic/agent.py
====================

from dataclasses import dataclass
from typing import Any, Dict, Optional
import logging

from .memory import AgentMemory
from .principles import PrincipleStore
from .tools import (
    AgentTools,
    MasteryVectorError,
    MasteryVectorTimeoutError,
    KnowledgeGraphError,
    KnowledgeGraphTimeoutError,
    RecommenderError,
    RecommenderTimeoutError,
)

# Configure logging
logger = logging.getLogger(__name__)


@dataclass
class AgentPlan:
    """
    Learning plan returned by the agentic planner.
    
    The agent is now a "learning agent" that determines WHAT to learn,
    not just HOW to generate cards.
    """
    learner_level: str
    topic: Optional[str]  # May be None if determined by recommender
    topic_complexity: Optional[str]
    scaffold_type: Optional[str]  # Determined by recommender or principles
    rationale: str
    cognitive_prior: Dict[str, Any]  # The synthesized cognitive state
    recommendation_plan: Optional[Dict[str, Any]] = None  # Plan from recommender
    cards_payload: Optional[Dict[str, Any]] = None  # Generated cards if needed


class AgenticPlanner:
    """
    Cognitive State Synthesis Engine - A Learning Agent, not just a card generator.
    
    This agent:
    1. Queries mastery vector (from Anki review history)
    2. Queries world model (knowledge graph)
    3. Queries user profile (from memory)
    4. Synthesizes a "cognitive prior" (best estimate of child's cognitive state)
    5. Calls the recommender with this prior to determine WHAT to learn
    6. Returns a learning plan (not just cards)
    
    The agent solves "what to learn" by integrating with the recommender system.
    """

    def __init__(self, memory: Optional[AgentMemory] = None, principles: Optional[PrincipleStore] = None, tools: Optional[AgentTools] = None) -> None:
        self.memory = memory or AgentMemory()
        self.principles = principles or PrincipleStore()
        self.tools = tools or AgentTools()

    def synthesize_cognitive_prior(self, user_id: str, topic: Optional[str] = None) -> Dict[str, Any]:
        """
        Synthesize the cognitive prior by querying:
        - Mastery vector (what the child has mastered)
        - World model/KG (knowledge structure and dependencies)
        - User profile (preferences and learning style)

        This is the "best effort prior" of the child's cognitive state.

        Raises:
            MasteryVectorError: If mastery vector query fails (non-timeout)
            KnowledgeGraphError: If knowledge graph query fails (non-timeout)
        """
        # 1. Query mastery vector (from Anki review history)
        print("  üìä Querying mastery vector from Anki...")
        mastery_vector = {}
        try:
            mastery_vector = self.tools.query_mastery_vector(user_id)
            print(f"  ‚úÖ Mastery vector: {len(mastery_vector)} nodes")
        except MasteryVectorTimeoutError as e:
            # Graceful degradation for timeout - continue with empty vector
            logger.warning(f"Mastery vector query timed out for user {user_id}, continuing with empty vector")
            print(f"  ‚ö†Ô∏è  Mastery vector: timeout, using empty vector")
            mastery_vector = {}
        except MasteryVectorError as e:
            # Non-timeout error - re-raise to fail fast
            logger.error(f"Mastery vector query failed for user {user_id}: {e}")
            raise

        # 2. Query world model (knowledge graph)
        print(f"  üåê Querying knowledge graph{' for topic: ' + topic if topic else ''}...")
        kg_context = {}
        try:
            kg_context = self.tools.query_world_model(topic=topic)
            print("  ‚úÖ Knowledge graph context retrieved")
        except KnowledgeGraphTimeoutError as e:
            # Graceful degradation for timeout - continue with empty context
            logger.warning(f"Knowledge graph query timed out for topic '{topic}', continuing with empty context")
            print("  ‚ö†Ô∏è  Knowledge graph: timeout, using empty context")
            kg_context = {}
        except KnowledgeGraphError as e:
            # Non-timeout error - re-raise to fail fast
            logger.error(f"Knowledge graph query failed for topic '{topic}': {e}")
            raise
        
        # 3. Query user profile
        print("  üë§ Querying user profile...")
        profile = self.tools.query_user_profile(user_id, self.memory)
        print("  ‚úÖ User profile retrieved")
        
        # Synthesize the prior
        cognitive_prior = {
            "mastery_vector": mastery_vector,
            "kg_context": kg_context,
            "profile": profile,
            "mastery_summary": {
                "total_nodes": len(mastery_vector),
                "mastered_nodes": sum(1 for v in mastery_vector.values() if v >= 0.85),
                "weak_nodes": sum(1 for v in mastery_vector.values() if 0.0 < v < 0.45),
                "unlearned_nodes": sum(1 for v in mastery_vector.values() if v == 0.0),
            },
        }
        
        return cognitive_prior

    def plan_learning_step(
        self,
        user_id: str,
        topic: Optional[str] = None,
        learner_level: Optional[str] = None,
        topic_complexity: Optional[str] = None,
    ) -> AgentPlan:
        """
        Plan a learning step by:
        1. Synthesizing cognitive prior
        2. Calling recommender with the prior
        3. Generating content if needed
        
        The agent determines WHAT to learn, not just generates cards for a given topic.
        """
        # Get user profile
        profile = self.memory.get_profile(user_id)
        resolved_level = learner_level or profile.get("level") or "novice"
        
        # STEP 1: Synthesize cognitive prior
        print("üîç Step 1: Synthesizing cognitive prior...")
        try:
            cognitive_prior = self.synthesize_cognitive_prior(user_id, topic)
            print(f"‚úÖ Cognitive prior synthesized: {len(cognitive_prior.get('mastery_vector', {}))} nodes tracked")
        except (MasteryVectorError, KnowledgeGraphError) as e:
            # Critical service failure - re-raise to API layer
            logger.error(f"Failed to synthesize cognitive prior for user {user_id}: {e}")
            raise

        # STEP 2: Call recommender with the prior
        print("üéØ Step 2: Calling recommender to determine next learning step...")
        try:
            recommendation_plan = self.tools.call_recommender(
                user_id=user_id,
                cognitive_prior=cognitive_prior,
            )
            print(f"‚úÖ Recommender returned: {recommendation_plan.get('decision', 'UNKNOWN')} - {recommendation_plan.get('plan_title', 'No plan')}")
        except RecommenderTimeoutError as e:
            # Recommender already returns fallback for timeout, but catch just in case
            logger.warning(f"Recommender timeout for user {user_id}, using fallback plan")
            recommendation_plan = {
                "decision": "REVIEW",
                "plan_title": "Unable to generate recommendations (timeout)",
                "learning_task": "rest",
                "task_details": {},
                "recommendations": [],
                "timeout": True,
            }
            print("  ‚ö†Ô∏è  Recommender: timeout, using fallback plan")
        except RecommenderError as e:
            # Non-timeout recommender error - re-raise to fail fast
            logger.error(f"Recommender failed for user {user_id}: {e}")
            raise
        
        # STEP 3: Generate rationale based on the synthesis
        mastery_summary = cognitive_prior.get("mastery_summary", {})
        rationale = (
            f"Analyzed cognitive state: {mastery_summary.get('mastered_nodes', 0)} mastered, "
            f"{mastery_summary.get('weak_nodes', 0)} weak areas, "
            f"{mastery_summary.get('unlearned_nodes', 0)} unlearned nodes. "
            f"Recommender decision: {recommendation_plan.get('decision', 'UNKNOWN')}. "
            f"Plan: {recommendation_plan.get('plan_title', 'No plan')}."
        )
        
        # STEP 4: Generate cards if the plan requires it
        cards_result = None
        task_details = recommendation_plan.get("task_details", {})
        scaffold_type = task_details.get("type")
        
        if scaffold_type and recommendation_plan.get("learning_task") == "scaffold":
            # Generate flashcards for the recommended learning task
            recommended_node = recommendation_plan.get("recommendations", [{}])[0] if recommendation_plan.get("recommendations") else {}
            node_label = recommended_node.get("label", topic or "learning content")
            
            prompt = f"Create {scaffold_type} practice for '{node_label}'."
            context_tags = {
                "type": scaffold_type,
                "node_id": recommended_node.get("node_id"),
                "level": resolved_level,
            }
            cards_result = self.tools.generate_flashcards(
                prompt=prompt,
                context_tags=context_tags,
                child_profile=profile or {},
            )
        
        # Determine topic from recommendation if not provided
        final_topic = topic
        if not final_topic and recommendation_plan.get("recommendations"):
            final_topic = recommendation_plan["recommendations"][0].get("label")
        
        # Determine complexity from mastery if not provided
        final_complexity = topic_complexity
        if not final_complexity:
            # Infer complexity from mastery levels
            mastery_values = list(cognitive_prior.get("mastery_vector", {}).values())
            if mastery_values:
                avg_mastery = sum(mastery_values) / len(mastery_values)
            else:
                avg_mastery = 0.5  # Default for empty mastery vector
            if avg_mastery < 0.3:
                final_complexity = "high"
            elif avg_mastery < 0.6:
                final_complexity = "medium"
            else:
                final_complexity = "low"
        
        plan = AgentPlan(
            learner_level=resolved_level,
            topic=final_topic,
            topic_complexity=final_complexity,
            scaffold_type=scaffold_type,
            rationale=rationale,
            cognitive_prior=cognitive_prior,
            recommendation_plan=recommendation_plan,
            cards_payload=cards_result,
        )
        
        # Update memory with this interaction
        self.memory.append_history(
            user_id,
            {
                "topic": final_topic,
                "scaffold": scaffold_type,
                "decision": recommendation_plan.get("decision"),
                "plan_title": recommendation_plan.get("plan_title"),
                "reason": rationale,
            },
        )
        self.memory.update_profile(user_id, {"level": resolved_level})
        
        return plan




====================
FILE: agentic/principles.py
====================

from typing import Any, Dict, List

import yaml

from .config import PRINCIPLES_FILE


DEFAULT_RULES = {
    "scaffolding": {
        "high_load": {
            "novice": "mcq",
            "intermediate": "cloze",
            "advanced": "free_response",
        },
        "default": "mcq",
    }
}


class PrincipleStore:
    """
    Lightweight principle repository backed by YAML.

    The file can be edited without changing code, and it forms the
    knowledge base that the agent consults before taking action.
    """

    def __init__(self) -> None:
        if PRINCIPLES_FILE.exists():
            self._rules = self._load()
        else:
            self._rules = DEFAULT_RULES
            self._save(DEFAULT_RULES)

    def _load(self) -> Dict[str, Any]:
        try:
            with open(PRINCIPLES_FILE, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f) or {}
        except yaml.YAMLError:
            data = {}
        if not data:
            data = DEFAULT_RULES
            self._save(data)
        return data

    def _save(self, data: Dict[str, Any]) -> None:
        with open(PRINCIPLES_FILE, "w", encoding="utf-8") as f:
            yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)

    @property
    def rules(self) -> Dict[str, Any]:
        return self._rules

    def select_scaffold(self, topic_complexity: str, learner_level: str) -> str:
        scaffolding = self._rules.get("scaffolding", {})
        high_load_rules = scaffolding.get("high_load", {})
        if topic_complexity == "high":
            return high_load_rules.get(learner_level) or high_load_rules.get("default") or scaffolding.get("default", "mcq")
        return scaffolding.get("default", "mcq")

    def debug_summary(self) -> List[str]:
        summary = []
        scaffolding = self._rules.get("scaffolding", {})
        summary.append("Scaffolding rules:")
        for key, value in scaffolding.items():
            summary.append(f"- {key}: {value}")
        return summary



