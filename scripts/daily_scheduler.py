#!/usr/bin/env python3
"""
CUMA (Lingxi) Daily Scheduler - åŸºäº PEP-3 çŸ­æ¿é¶å‘æ¨é€çš„æ™ºèƒ½è°ƒåº¦å™¨

æ ¸å¿ƒé€»è¾‘ï¼š
1. ä» SQLite profiles è¡¨è¯»å– extracted_dataï¼Œè§£æ pep3_baselineï¼Œæ‰¾å‡ºæœ€çŸ­æ¿é¢†åŸŸ
2. è·¨å›¾è°± SPARQL æŸ¥è¯¢ï¼šå‘½ä¸­è¯¥é¢†åŸŸçš„ PhasalObjective ä»»åŠ¡ä½œä¸ºé¶å‘å€™é€‰æ± 
3. ç»“åˆ FSRS è®°å¿†çŠ¶æ€ï¼Œä¼˜å…ˆæ¨é€åˆ°æœŸæˆ–æœªåšè¿‡çš„é¶å‘ä»»åŠ¡

ç”¨æ³•ï¼š
    # ç”Ÿæˆæ¯æ—¥é¶å‘ä»»åŠ¡ï¼ˆé»˜è®¤ï¼‰
    python scripts/daily_scheduler.py [--child å°æ˜] [--date 2026-02-27] [--count 3]

    # è®°å½•å®¶é•¿åé¦ˆ
    python scripts/daily_scheduler.py record <quest_id> <å…¨è¾…åŠ©|éƒ¨åˆ†è¾…åŠ©|ç‹¬ç«‹å®Œæˆ> [--child å°æ˜]

ä¾èµ–ï¼špip install fsrs rdflib
"""
from __future__ import annotations

import argparse
import json
import sqlite3
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Optional

# é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = Path(__file__).resolve().parent.parent

# PEP-3 é¢†åŸŸä»£ç  â†’ å›¾è°± domain URI åç¼€ æ˜ å°„
DOMAIN_CODE_TO_URI_SUFFIX: dict[str, str] = {
    "CVP": "domain_cvp",   # è®¤çŸ¥(è¯­è¨€/è¯­å‰)
    "EL": "domain_el",     # è¯­è¨€è¡¨è¾¾
    "RL": "domain_rl",     # è¯­è¨€ç†è§£
    "FM": "domain_fm",     # å°è‚Œè‚‰
    "GM": "domain_gm",     # å¤§è‚Œè‚‰
    "VMI": "domain_vmi",   # æ¨¡ä»¿(è§†è§‰/åŠ¨ä½œ)
    "AE": "domain_ae",     # æƒ…æ„Ÿè¡¨è¾¾
    "SR": "domain_sr",     # ç¤¾äº¤äº’åŠ¨
    "CMB": "domain_cmb",   # è¡Œä¸ºç‰¹å¾-éè¯­è¨€
    "CVB": "domain_cvb",   # è¡Œä¸ºç‰¹å¾-è¯­è¨€
}


def get_db_path() -> Path:
    """è·å– content_db ä¸‹çš„ SQLite è·¯å¾„ï¼ˆä¸ backend é…ç½®ä¸€è‡´ï¼‰ã€‚"""
    # ä¼˜å…ˆ content_dbï¼Œå…¶æ¬¡ data
    for subdir in ("content_db", ""):
        base = BASE_DIR / "data" / subdir if subdir else BASE_DIR / "data"
        db_path = base / "srs4autism.db"
        if db_path.exists():
            return db_path
    return BASE_DIR / "data" / "content_db" / "srs4autism.db"


def find_child_profile(db_path: Path, child_query: str) -> Optional[tuple[str, str, dict]]:
    """
    ä» SQLite æŸ¥æ‰¾å„¿ç«¥æ¡£æ¡ˆã€‚æ”¯æŒæ¨¡ç³ŠåŒ¹é… name æˆ–ç²¾ç¡® idã€‚
    è¿”å›: (profile_id, name, extracted_data_dict) æˆ– None
    """
    conn = sqlite3.connect(str(db_path))
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    cur.execute(
        "SELECT id, name, extracted_data FROM profiles WHERE id LIKE ? OR name LIKE ?",
        (f"%{child_query}%", f"%{child_query}%"),
    )
    row = cur.fetchone()
    conn.close()
    if not row:
        return None
    raw = row["extracted_data"]
    data = json.loads(raw) if raw else {}
    return (row["id"], row["name"], data)


def find_weakest_domain(extracted_data: dict) -> Optional[tuple[str, str, int]]:
    """
    ä» extracted_data è§£æ pep3_baselineï¼Œæ‰¾å‡º age_equivalent_months æœ€ä½çš„é¢†åŸŸã€‚
    è¿”å›: (domain_code, domain_name, age_months) æˆ– None
    """
    baseline = extracted_data.get("pep3_baseline", {})
    metrics = baseline.get("metrics", {})
    if not metrics:
        return None

    weakest_code: Optional[str] = None
    weakest_name: str = ""
    min_months: int = 9999

    for code, info in metrics.items():
        if not isinstance(info, dict):
            continue
        months = info.get("age_equivalent_months")
        if months is None:
            continue
        try:
            m = int(months) if isinstance(months, (int, float)) else int(float(months))
        except (ValueError, TypeError):
            continue
        name = info.get("domain_name") or code
        if m < min_months:
            min_months = m
            weakest_code = code
            weakest_name = name

    if weakest_code is None:
        return None
    return (weakest_code, weakest_name, min_months)


def load_graph():
    """åŠ è½½ ECTA + PEP-3 çŸ¥è¯†å›¾è°±ã€‚"""
    from rdflib import Graph

    g = Graph()
    quest_path = BASE_DIR / "knowledge_graph" / "quest_full.ttl"
    pep3_path = BASE_DIR / "knowledge_graph" / "pep3_master.ttl"

    if not quest_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° quest_full.ttl: {quest_path}")
    if not pep3_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° pep3_master.ttl: {pep3_path}")

    g.parse(str(quest_path), format="turtle")
    g.parse(str(pep3_path), format="turtle")
    return g


def get_targeted_quests(graph, domain_code: str) -> list[dict]:
    """
    è·¨å›¾è°± SPARQLï¼šæŸ¥è¯¢æ‰€æœ‰é€šè¿‡ alignsWithStandard å‘½ä¸­è¯¥é¢†åŸŸçš„ PhasalObjective ä»»åŠ¡ã€‚
    è¿”å›: [{quest_id, label, pep3_items, pep3_item_nums, suggested_materials}, ...]
    """
    uri_suffix = DOMAIN_CODE_TO_URI_SUFFIX.get(domain_code.upper())
    if not uri_suffix:
        return []

    domain_uri = f"http://ecta.ai/pep3/instance/{uri_suffix}"

    sparql = f"""
    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
    PREFIX ecta-kg: <http://ecta.ai/schema/>
    PREFIX ecta-inst: <http://ecta.ai/instance/>
    PREFIX pep3: <http://ecta.ai/pep3/schema/>
    PREFIX pep3-inst: <http://ecta.ai/pep3/instance/>

    SELECT ?task ?taskLabel ?pep3Item ?pep3Label ?itemNum ?material
           ?teachingSteps ?groupClassGeneralization ?homeGeneralization
    WHERE {{
        ?task a ecta-kg:PhasalObjective ;
              ecta-kg:alignsWithStandard ?pep3Item ;
              rdfs:label ?taskLabel .
        ?pep3Item pep3:belongsToDomain <{domain_uri}> ;
                  pep3:itemNumber ?itemNum ;
                  rdfs:label ?pep3Label .
        OPTIONAL {{ ?task ecta-kg:suggestedMaterials ?material . }}
        OPTIONAL {{ ?task ecta-kg:teachingSteps ?teachingSteps . }}
        OPTIONAL {{ ?task ecta-kg:groupClassGeneralization ?groupClassGeneralization . }}
        OPTIONAL {{ ?task ecta-kg:homeGeneralization ?homeGeneralization . }}
    }}
    """

    results = list(graph.query(sparql))

    # æŒ‰ task èšåˆ
    task_data: dict[str, dict] = {}
    for row in results:
        task_uri = str(row.task)
        task_id = task_uri.split("/")[-1] if "/" in task_uri else task_uri
        label = str(row.taskLabel) if row.taskLabel else task_id
        pep3_label = str(row.pep3Label) if row.pep3Label else ""
        item_num = row.itemNum
        material = str(row.material) if row.material else None
        teaching_steps = str(row.teachingSteps) if getattr(row, "teachingSteps", None) else None
        group_class_gen = str(row.groupClassGeneralization) if getattr(row, "groupClassGeneralization", None) else None
        home_gen = str(row.homeGeneralization) if getattr(row, "homeGeneralization", None) else None

        if task_id not in task_data:
            task_data[task_id] = {
                "quest_id": task_id,
                "label": label,
                "pep3_items": [],
                "pep3_item_nums": [],
                "suggested_materials": [],
                "teaching_steps": None,
                "group_class_generalization": None,
                "home_generalization": None,
            }
        if pep3_label and pep3_label not in task_data[task_id]["pep3_items"]:
            task_data[task_id]["pep3_items"].append(pep3_label)
            if item_num is not None:
                task_data[task_id]["pep3_item_nums"].append(int(item_num))
        if material and material not in task_data[task_id]["suggested_materials"]:
            task_data[task_id]["suggested_materials"].append(material)
        if teaching_steps:
            task_data[task_id]["teaching_steps"] = teaching_steps
        if group_class_gen:
            task_data[task_id]["group_class_generalization"] = group_class_gen
        if home_gen:
            task_data[task_id]["home_generalization"] = home_gen

    return list(task_data.values())


def get_child_profile_path(child_name: str) -> Path:
    """å„¿ç«¥ FSRS çŠ¶æ€æ¡£æ¡ˆè·¯å¾„ã€‚"""
    profiles_dir = BASE_DIR / "data" / "child_profiles"
    profiles_dir.mkdir(parents=True, exist_ok=True)
    return profiles_dir / f"{child_name}.json"


def load_child_profile(child_name: str) -> dict:
    """åŠ è½½å„¿ç«¥ FSRS çŠ¶æ€æ¡£æ¡ˆã€‚"""
    path = get_child_profile_path(child_name)
    if path.exists():
        with open(path, encoding="utf-8") as f:
            return json.load(f)
    return {"child_name": child_name, "quest_cards": {}, "created_at": datetime.now(timezone.utc).isoformat()}


def save_child_profile(child_name: str, profile: dict) -> None:
    """ä¿å­˜å„¿ç«¥æ¡£æ¡ˆã€‚"""
    path = get_child_profile_path(child_name)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(profile, f, ensure_ascii=False, indent=2)


def prompt_level_to_fsrs_rating(prompt_level: str) -> int:
    """ç‰¹æ•™è¾…åŠ©å±‚çº§ â†’ FSRS Rating æ˜ å°„ã€‚"""
    mapping = {"å…¨è¾…åŠ©": 1, "éƒ¨åˆ†è¾…åŠ©": 2, "ç‹¬ç«‹å®Œæˆ": 3}
    return mapping.get(prompt_level, 3)


def _parse_due_from_fsrs_state(state: dict) -> Optional[datetime]:
    """ä» fsrs_states ä¸­çš„å•æ¡è®°å½•è§£æ due æ—¥æœŸã€‚"""
    due_val = state.get("due")
    if due_val is None:
        return None
    if isinstance(due_val, datetime):
        return due_val
    if isinstance(due_val, str):
        try:
            return datetime.fromisoformat(due_val.replace("Z", "+00:00"))
        except ValueError:
            return None
    return None


def run_targeted_scheduler(
    child_name: str,
    target_date: datetime,
    count: int = 3,
    db_path: Optional[Path] = None,
) -> tuple[list[dict], Optional[tuple[str, str, int]]]:
    """
    è¿è¡Œé¶å‘è°ƒåº¦ï¼šæ‰¾æœ€çŸ­æ¿ â†’ SPARQL é¶å‘ä»»åŠ¡æ±  â†’ ä¸¥æ ¼ FSRS è¿‡æ»¤ â†’ æ’åºã€‚
    ä¸¥æ ¼ä» extracted_data['fsrs_states'] è¯»å–ï¼šdue > --date çš„ä»»åŠ¡åšå†³å‰”é™¤ã€‚
    è¿”å›: (selected_quests, weakest_domain_info)
    """
    from fsrs import FSRS, Card

    db_path = db_path or get_db_path()
    profile_row = find_child_profile(db_path, child_name)

    weakest: Optional[tuple[str, str, int]] = None
    fsrs_states: dict = {}
    if profile_row:
        _, _, extracted = profile_row
        weakest = find_weakest_domain(extracted)
        fsrs_states = extracted.get("fsrs_states") or {}

    graph = load_graph()

    if weakest:
        domain_code, domain_name, age_months = weakest
        quest_pool = get_targeted_quests(graph, domain_code)
        if not quest_pool:
            quest_pool = _get_fallback_quest_pool(graph)
    else:
        quest_pool = _get_fallback_quest_pool(graph)

    target_date_d = target_date.date()
    target_dt = target_date.replace(hour=0, minute=0, second=0, microsecond=0)
    due_quests: list[tuple[datetime, dict, Card | None]] = []

    for quest in quest_pool:
        qid = quest["quest_id"]
        card_data = fsrs_states.get(qid)

        if card_data:
            due = _parse_due_from_fsrs_state(card_data)
            if due is not None and due.date() > target_date_d:
                continue
            try:
                card = Card.from_dict(card_data)
            except Exception:
                card = Card()
            sort_due = due if due else target_dt
            due_quests.append((sort_due, quest, card))
        else:
            card = Card()
            due_quests.append((target_dt, quest, card))

    def _sort_key(item: tuple) -> float:
        d = item[0]
        if d.tzinfo is None:
            d = d.replace(tzinfo=timezone.utc)
        return d.timestamp()

    due_quests.sort(key=_sort_key)
    selected = due_quests[:count]
    return [{"quest": q, "card": c, "due": d} for d, q, c in selected], weakest


def _get_fallback_quest_pool(graph) -> list[dict]:
    """æ— æœ€çŸ­æ¿æˆ–é¶å‘æ± ä¸ºç©ºæ—¶ï¼Œè¿”å›å…¨éƒ¨æœ‰ alignsWithStandard çš„ä»»åŠ¡ã€‚"""
    sparql = """
    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
    PREFIX ecta-kg: <http://ecta.ai/schema/>
    PREFIX ecta-inst: <http://ecta.ai/instance/>

    SELECT ?task ?taskLabel ?pep3Label ?material
           ?teachingSteps ?groupClassGeneralization ?homeGeneralization
    WHERE {
        ?task a ecta-kg:PhasalObjective ;
              ecta-kg:alignsWithStandard ?pep3Item ;
              rdfs:label ?taskLabel .
        ?pep3Item rdfs:label ?pep3Label .
        OPTIONAL { ?task ecta-kg:suggestedMaterials ?material . }
        OPTIONAL { ?task ecta-kg:teachingSteps ?teachingSteps . }
        OPTIONAL { ?task ecta-kg:groupClassGeneralization ?groupClassGeneralization . }
        OPTIONAL { ?task ecta-kg:homeGeneralization ?homeGeneralization . }
    }
    """
    results = list(graph.query(sparql))
    task_data: dict[str, dict] = {}
    for row in results:
        task_uri = str(row.task)
        task_id = task_uri.split("/")[-1] if "/" in task_uri else task_uri
        label = str(row.taskLabel) if row.taskLabel else task_id
        pep3_label = str(row.pep3Label) if row.pep3Label else ""
        material = str(row.material) if row.material else None
        teaching_steps = str(row.teachingSteps) if getattr(row, "teachingSteps", None) else None
        group_class_gen = str(row.groupClassGeneralization) if getattr(row, "groupClassGeneralization", None) else None
        home_gen = str(row.homeGeneralization) if getattr(row, "homeGeneralization", None) else None
        if task_id not in task_data:
            task_data[task_id] = {
                "quest_id": task_id,
                "label": label,
                "pep3_items": [],
                "pep3_item_nums": [],
                "suggested_materials": [],
                "teaching_steps": None,
                "group_class_generalization": None,
                "home_generalization": None,
            }
        if pep3_label and pep3_label not in task_data[task_id]["pep3_items"]:
            task_data[task_id]["pep3_items"].append(pep3_label)
            if "." in str(pep3_label):
                try:
                    num = int(pep3_label.split(".")[0].strip())
                    task_data[task_id]["pep3_item_nums"].append(num)
                except ValueError:
                    pass
        if material and material not in task_data[task_id]["suggested_materials"]:
            task_data[task_id]["suggested_materials"].append(material)
        if teaching_steps:
            task_data[task_id]["teaching_steps"] = teaching_steps
        if group_class_gen:
            task_data[task_id]["group_class_generalization"] = group_class_gen
        if home_gen:
            task_data[task_id]["home_generalization"] = home_gen
    return list(task_data.values())


def format_pep3_short(quest: dict) -> str:
    """ç”Ÿæˆ PEP-3 é¢˜å·ç®€å†™ï¼Œå¦‚ '86é¢˜ã€133é¢˜'ã€‚"""
    nums = quest.get("pep3_item_nums")
    if nums:
        return "ã€".join(f"{n}é¢˜" for n in sorted(set(nums)))
    items = quest.get("pep3_items", [])
    if items:
        parts = []
        for p in items:
            if "." in str(p):
                parts.append(p.split(".")[0].strip() + "é¢˜")
        return "ã€".join(parts) if parts else "ã€".join(items)
    return "â€”"


def format_materials(quest: dict) -> str:
    """æ ¼å¼åŒ–æ¨èæ•™å…·ã€‚"""
    mats = quest.get("suggested_materials", [])
    if mats:
        return "ã€".join(mats)
    return "åˆ©ç”¨è‡ªç„¶ç¯å¢ƒ"


def print_daily_quests(
    child_name: str,
    target_date: datetime,
    count: int = 3,
    db_path: Optional[Path] = None,
) -> None:
    """åœ¨ç»ˆç«¯æ‰“å°é¶å‘ Daily Questsã€‚"""
    results, weakest = run_targeted_scheduler(child_name, target_date, count, db_path)
    date_str = target_date.strftime("%Y-%m-%d")

    # è§£ææ˜¾ç¤ºç”¨ child åç§°ï¼ˆä¼˜å…ˆ DB ä¸­çš„ nameï¼‰
    db_path = db_path or get_db_path()
    profile_row = find_child_profile(db_path, child_name)
    display_name = profile_row[1] if profile_row else child_name

    print()
    print("=" * 64)
    print(f"ğŸ“… ä»Šå¤©æ˜¯ {date_str}ï¼Œ{display_name} çš„é¶å‘ Daily Questsï¼š")
    if weakest:
        domain_code, domain_name, age_months = weakest
        print(f"ğŸ“Š ç®—æ³•è¯Šæ–­ï¼šå½“å‰æœ€çŸ­æ¿ä¸ºã€{domain_name} ({domain_code})ã€‘(å¹´é¾„å½“é‡{age_months}ä¸ªæœˆ)ï¼Œå·²å€¾æ–œæ¨èæƒé‡ã€‚")
    else:
        print("ğŸ“Š ç®—æ³•è¯Šæ–­ï¼šæœªæ£€æµ‹åˆ° PEP-3 åŸºçº¿æ•°æ®ï¼Œä½¿ç”¨å…¨ä»»åŠ¡æ± æ¨èã€‚")
    print("=" * 64)

    for i, item in enumerate(results, 1):
        quest = item["quest"]
        task_id = quest["quest_id"]
        pep3_short = format_pep3_short(quest)
        materials = format_materials(quest)
        print(f"\n{i}. [{task_id}] {quest['label']} â€”â€” ğŸ¯ æ”¯æ’‘ PEP-3 {pep3_short}")
        print(f"   â†³ æ¨èæ•™å…·ï¼š{materials}")

    print("\n" + "=" * 64)
    print("ğŸ’¡ å®¶é•¿åé¦ˆåï¼Œç³»ç»Ÿå°†æ˜ å°„ä¸º FSRS è¯„çº§å¹¶æ›´æ–°ä¸‹æ¬¡å¤ä¹ æ—¶é—´ã€‚")
    print("=" * 64 + "\n")


def record_feedback(
    child_name: str,
    quest_id: str,
    prompt_level: str,
    db_path: Optional[Path] = None,
) -> None:
    """è®°å½•å®¶é•¿åé¦ˆå¹¶çœŸå®æ›´æ–°è‡³ SQLite æ•°æ®åº“çš„ FSRS çŠ¶æ€ä¸­ã€‚"""
    from fsrs import FSRS, Card, Rating

    db_path = db_path or get_db_path()
    profile_row = find_child_profile(db_path, child_name)

    if not profile_row:
        raise ValueError(f"æ‰¾ä¸åˆ°å„¿ç«¥æ¡£æ¡ˆ: {child_name}")

    profile_id, name, extracted = profile_row

    # è·å–æˆ–åˆå§‹åŒ–æ•°æ®åº“ä¸­çš„ fsrs_states
    fsrs_states = extracted.setdefault("fsrs_states", {})
    scheduler = FSRS()

    # è¯»å–å¡ç‰‡å†å²çŠ¶æ€
    card_data = fsrs_states.get(quest_id)
    card = Card.from_dict(card_data) if card_data else Card()

    # FSRS è¦æ±‚ï¼šstate != New æ—¶å¿…é¡»æœ‰ last_reviewï¼Œå¦åˆ™ review_card ä¼šæŠ¥é”™
    if card.state != 0 and not getattr(card, "last_review", None):
        card.last_review = card.due

    # æ˜ å°„è¯„çº§å¹¶å¤ä¹ 
    rating_val = prompt_level_to_fsrs_rating(prompt_level)
    rating = Rating(rating_val)
    new_card, _ = scheduler.review_card(card, rating)

    # å°†æ›´æ–°åçš„å¡ç‰‡å­˜å› extracted_data
    fsrs_states[quest_id] = new_card.to_dict()
    extracted["fsrs_states"] = fsrs_states

    # æ‰§è¡Œ SQL çœŸæ­£è½ç›˜åˆ°æ•°æ®åº“
    conn = sqlite3.connect(str(db_path))
    cur = conn.cursor()
    now_str = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
    cur.execute(
        "UPDATE profiles SET extracted_data = ?, updated_at = ? WHERE id = ?",
        (json.dumps(extracted, ensure_ascii=False), now_str, profile_id),
    )
    conn.commit()
    conn.close()

    print(f"âœ… å·²æŒä¹…åŒ–è®°å½•ï¼š{quest_id} â†’ {prompt_level} (FSRS {rating_val})")
    due_str = new_card.due.strftime("%Y-%m-%d") if new_card.due else "â€”"
    print(f"ğŸ“… è¯¥ä»»åŠ¡ä¸‹æ¬¡å¤ä¹ æ—¶é—´å·²æ¨è¿Ÿè‡³: {due_str}")


def main() -> None:
    parser = argparse.ArgumentParser(description="CUMA é¶å‘æ¯æ—¥ä»»åŠ¡è°ƒåº¦å™¨ (PEP-3 çŸ­æ¿)")
    parser.add_argument("--child", default="å°æ˜", help="å„¿ç«¥å§“åæˆ– IDï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰")
    parser.add_argument("--date", default=None, help="ç›®æ ‡æ—¥æœŸ YYYY-MM-DD")
    parser.add_argument("--count", type=int, default=3, help="æ¯æ—¥ä»»åŠ¡æ•°é‡")
    parser.add_argument("--db", default=None, help="SQLite æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ data/content_db/srs4autism.dbï¼‰")
    subparsers = parser.add_subparsers(dest="cmd", help="å­å‘½ä»¤")

    subparsers.add_parser("schedule", help="ç”Ÿæˆæ¯æ—¥é¶å‘ä»»åŠ¡ (é»˜è®¤)")
    sp_record = subparsers.add_parser("record", help="è®°å½•å®¶é•¿åé¦ˆ")
    sp_record.add_argument("quest_id", help="ä»»åŠ¡ IDï¼Œå¦‚ task_1001")
    sp_record.add_argument(
        "prompt_level",
        choices=["å…¨è¾…åŠ©", "éƒ¨åˆ†è¾…åŠ©", "ç‹¬ç«‹å®Œæˆ"],
        help="å®¶é•¿åé¦ˆçš„è¾…åŠ©å±‚çº§",
    )

    args = parser.parse_args()
    db_path = Path(args.db) if args.db else None

    if args.cmd is None or args.cmd == "schedule":
        target = datetime.strptime(args.date, "%Y-%m-%d") if args.date else datetime.now()
        print_daily_quests(args.child, target, args.count, db_path)
    elif args.cmd == "record":
        record_feedback(args.child, args.quest_id, args.prompt_level, db_path)


if __name__ == "__main__":
    main()
